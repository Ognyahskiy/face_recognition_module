{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53fc078a-3f9f-46c8-8140-9c8d6bbc3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 04:04:31.015930: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-20 04:04:31.015995: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-20 04:04:31.069078: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-20 04:04:31.180953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 04:04:32.193098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "import cv2 as cv\n",
    "import dlib\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "324a08c9-dfe3-4d35-a264-a115a267f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"VGG-Face\",\n",
    "    \"Facenet\",\n",
    "    \"Facenet512\",\n",
    "    \"OpenFace\",\n",
    "    \"DeepFace\",\n",
    "    \"DeepID\",\n",
    "    \"ArcFace\",\n",
    "    \"Dlib\",\n",
    "    \"SFace\",\n",
    "    \"GhostFaceNet\",\n",
    "]\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "backends = [\n",
    "    \"opencv\",\n",
    "    \"ssd\",\n",
    "    \"dlib\",\n",
    "    \"mtcnn\",\n",
    "    \"fastmtcnn\",\n",
    "    \"retinaface\",\n",
    "    \"mediapipe\",\n",
    "    \"yolov8\",\n",
    "    \"yunet\",\n",
    "    \"centerface\",\n",
    "    \"skip\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290b8c21-a362-431b-8ea2-3043a6139471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bb(rect):  # convert dlib coords into opencv\n",
    "    startX = rect.left()\n",
    "    startY = rect.top()\n",
    "    endX = rect.right()\n",
    "    endY = rect.bottom()\n",
    "    w = endX - startX\n",
    "    h = endY - startY\n",
    "    return (startX, startY, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aaf5b29-a064-46fe-a1bb-26ab82a339d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()  # setup detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46c9469f-5e70-4084-8986-9210ce28898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_face_recognition(img):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    faces = [convert_bb(r) for r in faces]\n",
    "    for x, y, h, w in faces:\n",
    "        face = DeepFace.find(\n",
    "            img_path=img[y : y + h, x : x + w],\n",
    "            db_path=\"200classes_data/train\",\n",
    "            model_name=models[1],\n",
    "            distance_metric=metrics[0],\n",
    "            detector_backend=backends[10],\n",
    "            enforce_detection=False,\n",
    "            normalization=\"Facenet2018\",\n",
    "            align=True,\n",
    "            silent=True,\n",
    "        )\n",
    "        try:\n",
    "            person = (\n",
    "                face[0]\n",
    "                .identity.head(3)\n",
    "                .apply(lambda x: x.split(\"/\")[2])\n",
    "                .agg({\"identity\": \"value_counts\"})\n",
    "                .idxmax()[1]\n",
    "            )\n",
    "        except Exception:\n",
    "            person = \"Stranger\"\n",
    "        print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb0a2336-cbd4-4933-ab32-c0b1fb51522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5b870ac-80eb-4ecc-b861-19e5dff28a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colin_Powell\n"
     ]
    }
   ],
   "source": [
    "basic_face_recognition(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f0c97ec-69cc-4028-bfbf-77482027be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(base_path, db_path):\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "    expected = []\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            img = cv.imread(file_path)\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            faces = detector(gray)\n",
    "            faces = [convert_bb(r) for r in faces]\n",
    "            for x, y, h, w in faces:\n",
    "                face = DeepFace.find(\n",
    "                    img_path=img[y : y + h, x : x + w],\n",
    "                    db_path=db_path,\n",
    "                    model_name=models[1],\n",
    "                    distance_metric=metrics[0],\n",
    "                    detector_backend=backends[10],\n",
    "                    enforce_detection=False,\n",
    "                    normalization=\"Facenet2018\",\n",
    "                    align=True,\n",
    "                    silent=True,\n",
    "                )\n",
    "                try:\n",
    "                    person = (\n",
    "                        face[0]\n",
    "                        .identity.head(3)\n",
    "                        .apply(lambda x: x.split(\"/\")[2])\n",
    "                        .agg({\"identity\": \"value_counts\"})\n",
    "                        .idxmax()[1]\n",
    "                    )\n",
    "                except Exception:\n",
    "                    person = \"Stranger\"\n",
    "                predictions.append(person)\n",
    "                expected.append(folder_name)\n",
    "                counter += 1\n",
    "    print(f\"Done {base_path}\")\n",
    "    return accuracy_score(predictions, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959dcfaa-e36b-40bc-8179-722df78cdd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 200classes_data/test\n",
      "Done 150classes_data/test\n",
      "Done 100classes_data/test\n",
      "Done 50classes_data/test\n"
     ]
    }
   ],
   "source": [
    "accuracy_200 = accuracy(\"200classes_data/test\", \"200classes_data/train\")\n",
    "accuracy_150 = accuracy(\"150classes_data/test\", \"150classes_data/train\")\n",
    "accuracy_100 = accuracy(\"100classes_data/test\", \"100classes_data/train\")\n",
    "accuracy_50 = accuracy(\"50classes_data/test\", \"50classes_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349bd485-6fd0-4887-afa8-6060980e0e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560975609756097"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_200  # facenet2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c80dfb59-be4a-4a8d-a179-1194d43cee58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8146341463414634"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_200  # facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c1bad7ed-73a4-43fd-97e4-67a056bcd757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8306709265175719"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_150  # facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8afd8e3d-26a7-4487-821b-2e0411e2277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8722044728434505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_150  # facenet2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "719a75e6-3995-4634-b427-ced28d0ea885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734177215189873"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_100  # facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "392de218-f0ae-423f-8667-8d835eb1acb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9082278481012658"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_100  # facenet2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5d400deb-dc46-42d7-951f-806b0b4d7b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128787878787878"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_50  # facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa13384-3363-4652-b2d5-1e0cd1810183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128787878787878"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_50  # facenet2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a0ff3-8010-4a84-b3cc-386482d0ce1d",
   "metadata": {},
   "source": [
    "Точность модели на 200 классов:85.61%   \n",
    "Точность модели на 150 классов:87.2%   \n",
    "Точность модели на 100 классов:90.82%   \n",
    "Точность модели на 50 классов:91.28%   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c3d6811-678e-4a52-ad28-c3ff2d75523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"video.mp4\")\n",
    "\n",
    "cap2 = cv.VideoCapture(\"video2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "feee8d1c-6f21-4f3d-a1b3-7750a9ef97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of the recorded video\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_size = (frame_width, frame_height)\n",
    "fps = int(cap.get(cv.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cbe14937-2803-427c-a130-55ebfba91e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FaceRecognition(faceNames, faceID, frame):\n",
    "    print(\"Calling FaceRecognition\")\n",
    "    faces = DeepFace.find(\n",
    "        img_path=frame,\n",
    "        db_path=\"200classes_data/train\",\n",
    "        model_name=models[1],\n",
    "        distance_metric=metrics[0],\n",
    "        detector_backend=backends[10],\n",
    "        enforce_detection=False,\n",
    "        normalization=\"Facenet2018\",\n",
    "        silent=True\n",
    "    )\n",
    "    try:\n",
    "        person = (\n",
    "            faces[0]\n",
    "            .identity.head(3)\n",
    "            .apply(lambda x: x.split(\"/\")[2])\n",
    "            .agg({\"identity\": \"value_counts\"})\n",
    "            .idxmax()[1]\n",
    "        )\n",
    "    except Exception:\n",
    "        person = None\n",
    "    faceNames[faceID] = person\n",
    "    print(faceNames, faceID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1b48859f-8ad6-4291-a564-ea069da0e514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def face_tracking_and_recognition(cap):\n",
    "    #writer = cv.VideoWriter(\"result2_200classes.mp4\", cv.VideoWriter_fourcc(*'DIVX'), 60, frame_size)\n",
    "    frameCounter = 0\n",
    "    currentFaceID = 0\n",
    "    faceTrackers = {}\n",
    "    faceNames = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        resultFrame = frame.copy()\n",
    "\n",
    "        frameCounter += 1\n",
    "\n",
    "        faceIDsToDelete = []  # delete bad trackers\n",
    "        for faceID in faceTrackers.keys():\n",
    "            trackingQuality = faceTrackers[faceID].update(frame)\n",
    "            if trackingQuality < 7:\n",
    "                faceIDsToDelete.append(faceID)\n",
    "        for faceID in faceIDsToDelete:\n",
    "            faceTrackers.pop(faceID, None)\n",
    "\n",
    "        if (frameCounter % 10) == 0:  # start scanning for faces\n",
    "            gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            faces = detector(gray)\n",
    "            faces = [convert_bb(r) for r in faces]\n",
    "\n",
    "            for x, y, h, w in faces:\n",
    "                x_bar = x + 0.5 * w\n",
    "                y_bar = y + 0.5 * h\n",
    "                matchedFaceID = None\n",
    "\n",
    "                for faceID in faceTrackers.keys():\n",
    "                    tracked_position = faceTrackers[faceID].get_position()\n",
    "\n",
    "                    t_x = int(tracked_position.left())\n",
    "                    t_y = int(tracked_position.top())\n",
    "                    t_w = int(tracked_position.width())\n",
    "                    t_h = int(tracked_position.height())\n",
    "\n",
    "                    t_x_bar = t_x + 0.5 * t_w\n",
    "                    t_y_bar = t_y + 0.5 * t_h\n",
    "\n",
    "                    # if face center in tracked bbox and tracked center in face bbox we approved it\n",
    "                    if (\n",
    "                        (t_x <= x_bar <= (t_x + t_w))\n",
    "                        and (t_y <= y_bar <= (t_y + t_h))\n",
    "                        and (x <= t_x_bar <= (x + w))\n",
    "                        and (y <= t_y_bar <= (y + h))\n",
    "                    ):\n",
    "                        matchedFaceID = faceID\n",
    "\n",
    "                if matchedFaceID is None:\n",
    "                    currentFaceID += 1\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    tracker.start_track(\n",
    "                        frame,\n",
    "                        dlib.rectangle(x - 10, y - 20, x + w + 10, y + h + 20),\n",
    "                    )\n",
    "\n",
    "                    faceTrackers[currentFaceID] = tracker\n",
    "                    t_f = threading.Thread(\n",
    "                        target=FaceRecognition,\n",
    "                        args=(faceNames, currentFaceID, frame[y : y + h, x : x + w]),\n",
    "                        daemon=True,\n",
    "                    )\n",
    "                    t_f.start()\n",
    "            if frameCounter % 300 == 0:  # start face recognition periodically\n",
    "                for faceID in faceTrackers.keys():\n",
    "                    tracked_position = faceTrackers[faceID].get_position()\n",
    "\n",
    "                    t_x = int(tracked_position.left())\n",
    "                    t_y = int(tracked_position.top())\n",
    "                    t_w = int(tracked_position.width())\n",
    "                    t_h = int(tracked_position.height())\n",
    "                    t = threading.Thread(\n",
    "                        target=FaceRecognition,\n",
    "                        args=(\n",
    "                            faceNames,\n",
    "                            faceID,\n",
    "                            frame[t_y : t_y + t_w, t_x : t_x + t_h],\n",
    "                        ),\n",
    "                        daemon=True,\n",
    "                    )\n",
    "                    t.start()\n",
    "\n",
    "        for faceID in faceTrackers.keys():\n",
    "            tracked_position = faceTrackers[faceID].get_position()\n",
    "\n",
    "            t_x = int(tracked_position.left())\n",
    "            t_y = int(tracked_position.top())\n",
    "            t_w = int(tracked_position.width())\n",
    "            t_h = int(tracked_position.height())\n",
    "\n",
    "            cv.rectangle(\n",
    "                resultFrame, (t_x, t_y), (t_x + t_w, t_y + t_h), (0, 255, 0), 2\n",
    "            )\n",
    "\n",
    "            if faceID in faceNames.keys():\n",
    "                cv.putText(\n",
    "                    resultFrame,\n",
    "                    faceNames[faceID],\n",
    "                    (int(t_x + t_w / 2), int(t_y)),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (255, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "            else:\n",
    "                cv.putText(\n",
    "                    resultFrame,\n",
    "                    \"Detecting\",\n",
    "                    (int(t_x + t_w / 2), int(t_y)),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (255, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        #writer.write(resultFrame)\n",
    "        cv.imshow(\"result\", resultFrame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            cap.release()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0be9cd94-90d0-40e9-a235-5ce3a5fe2a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling FaceRecognition\n",
      "{1: None} 1\n",
      "Calling FaceRecognition\n",
      "{1: 'George_W_Bush'} 1\n",
      "Calling FaceRecognition\n",
      "{1: 'George_W_Bush'} 1\n"
     ]
    }
   ],
   "source": [
    "face_tracking_and_recognition(cap)\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce1e6c3e-5428-4796-878b-f1666e27947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454c41e-8f20-45b7-b43e-d1b0666b9c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
