{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fc078a-3f9f-46c8-8140-9c8d6bbc3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 23:06:46.383519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-17 23:06:46.383573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-17 23:06:46.384482: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-17 23:06:46.390063: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 23:06:47.101552: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import threading\n",
    "\n",
    "import cv2 as cv\n",
    "import dlib\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324a08c9-dfe3-4d35-a264-a115a267f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"VGG-Face\",\n",
    "    \"Facenet\",\n",
    "    \"Facenet512\",\n",
    "    \"OpenFace\",\n",
    "    \"DeepFace\",\n",
    "    \"DeepID\",\n",
    "    \"ArcFace\",\n",
    "    \"Dlib\",\n",
    "    \"SFace\",\n",
    "    \"GhostFaceNet\",\n",
    "]\n",
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "backends = [\n",
    "    \"opencv\",\n",
    "    \"ssd\",\n",
    "    \"dlib\",\n",
    "    \"mtcnn\",\n",
    "    \"fastmtcnn\",\n",
    "    \"retinaface\",\n",
    "    \"mediapipe\",\n",
    "    \"yolov8\",\n",
    "    \"yunet\",\n",
    "    \"centerface\",\n",
    "    \"skip\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290b8c21-a362-431b-8ea2-3043a6139471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bb(rect):  # convert dlib coords into opencv\n",
    "    startX = rect.left()\n",
    "    startY = rect.top()\n",
    "    endX = rect.right()\n",
    "    endY = rect.bottom()\n",
    "    w = endX - startX\n",
    "    h = endY - startY\n",
    "    return (startX, startY, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aaf5b29-a064-46fe-a1bb-26ab82a339d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()  # setup detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0a2336-cbd4-4933-ab32-c0b1fb51522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c9469f-5e70-4084-8986-9210ce28898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-04-17 22:15:21 - ⚠️ Representations for images in 200classes_data/train folder were previously stored in representations_facenet.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "24-04-17 22:15:21 - There are 1069 representations found in representations_facenet.pkl\n",
      "24-04-17 22:15:22 - find function lasts 0.8628864288330078 seconds\n",
      "Colin_Powell\n"
     ]
    }
   ],
   "source": [
    "faces = DeepFace.find(\n",
    "    img_path=img,\n",
    "    db_path=\"200classes_data/train\",\n",
    "    model_name=models[1],\n",
    "    distance_metric=metrics[0],\n",
    "    detector_backend=backends[2],\n",
    "    enforce_detection=False,\n",
    ")\n",
    "person = (\n",
    "    faces[0]\n",
    "    .identity.head(3)\n",
    "    .apply(lambda x: x.split(\"/\")[2])\n",
    "    .agg({\"identity\": \"value_counts\"})\n",
    "    .idxmax()[1]\n",
    ")\n",
    "print(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f0c97ec-69cc-4028-bfbf-77482027be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(base_path, db_path):\n",
    "    counter = 0\n",
    "    predictions = []\n",
    "    expected = []\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        for file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            face = DeepFace.find(\n",
    "                img_path=file_path,\n",
    "                db_path=db_path,\n",
    "                model_name=models[1],\n",
    "                distance_metric=metrics[0],\n",
    "                detector_backend=backends[2],\n",
    "                enforce_detection=False,\n",
    "            )\n",
    "            try:\n",
    "                person = (\n",
    "                    face[0]\n",
    "                    .identity.head(3)\n",
    "                    .apply(lambda x: x.split(\"/\")[2])\n",
    "                    .agg({\"identity\": \"value_counts\"})\n",
    "                    .idxmax()[1]\n",
    "                )\n",
    "            except ValueError:\n",
    "                person = \"Stranger\"\n",
    "            predictions.append(person)\n",
    "            expected.append(folder_name)\n",
    "            counter += 1\n",
    "            print(counter)\n",
    "    return accuracy_score(predictions, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "959dcfaa-e36b-40bc-8179-722df78cdd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#accuracy_200 = accuracy(\"200classes_data/test\", \"200classes_data/train\")\n",
    "#accuracy_150 = accuracy(\"150classes_data/test\", \"150classes_data/train\")\n",
    "#accuracy_100 = accuracy(\"100classes_data/test\", \"100classes_data/train\")\n",
    "#accuracy_50 = accuracy(\"50classes_data/test\", \"50classes_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc080bed-d434-461d-a4fd-c4de97d034be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75b68296-437c-49d0-a261-6e80b7cbaf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67c6aad8-cd99-4a95-801b-cd6728e110d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a725505-d04f-4702-b01a-0e82cce42bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a0ff3-8010-4a84-b3cc-386482d0ce1d",
   "metadata": {},
   "source": [
    "Точность модели на 200 классов:90.25%   \n",
    "Точность модели на 150 классов:93%   \n",
    "Точность модели на 100 классов:94.6%   \n",
    "Точность модели на 50 классов:96%   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c3d6811-678e-4a52-ad28-c3ff2d75523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feee8d1c-6f21-4f3d-a1b3-7750a9ef97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of the recorded video\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_size = (frame_width, frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec01a2a0-9db4-48f6-8957-ca0225779820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "writer = cv.VideoWriter(\"result.mp4\", cv.VideoWriter_fourcc(*\"DIVX\"), 60, frame_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe14937-2803-427c-a130-55ebfba91e08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def FaceRecognition(faceNames, faceID, frame):\n",
    "    faces = DeepFace.find(\n",
    "        img_path=frame,\n",
    "        db_path=\"200classes_data/train\",\n",
    "        model_name=models[1],\n",
    "        distance_metric=metrics[0],\n",
    "        detector_backend=backends[2],\n",
    "        enforce_detection=False,\n",
    "    )\n",
    "    try:\n",
    "        person = (\n",
    "            faces[0]\n",
    "            .identity.head(3)\n",
    "            .apply(lambda x: x.split(\"/\")[2])\n",
    "            .agg({\"identity\": \"value_counts\"})\n",
    "            .idxmax()[1]\n",
    "        )\n",
    "    except ValueError:\n",
    "        person = None\n",
    "    faceNames[faceID] = person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2738f841-e580-4530-ba24-4ae0d91ad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_function(faceNames, faceID, frame):\n",
    "    print(\"Calling FaceRecognition\")  # Отладочный вывод\n",
    "    FaceRecognition(faceNames, faceID, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b48859f-8ad6-4291-a564-ea069da0e514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def face_tracking_and_recognition(cap):\n",
    "\n",
    "    frameCounter = 0\n",
    "    currentFaceID = 0\n",
    "    faceTrackers = {}\n",
    "    faceNames = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        resultFrame = frame.copy()\n",
    "\n",
    "        frameCounter += 1\n",
    "        if frameCounter % 300 == 0:  # start face recognition periodically\n",
    "            t = threading.Thread(\n",
    "                target=thread_function,\n",
    "                args=(faceNames, currentFaceID, frame),\n",
    "                daemon=True,\n",
    "            )\n",
    "            t.start()\n",
    "\n",
    "        faceIDsToDelete = []  # delete bad trackers\n",
    "        for faceID in faceTrackers.keys():\n",
    "            trackingQuality = faceTrackers[faceID].update(frame)\n",
    "            if trackingQuality < 7:\n",
    "                faceIDsToDelete.append(faceID)\n",
    "        for faceID in faceIDsToDelete:\n",
    "            faceTrackers.pop(faceID, None)\n",
    "\n",
    "        if (frameCounter % 10) == 0:#start scanning for faces\n",
    "            gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            faces = detector(gray)\n",
    "            faces = [convert_bb(r) for r in faces]\n",
    "\n",
    "            for x, y, w, h in faces:\n",
    "                x_bar = x + 0.5 * w\n",
    "                y_bar = y + 0.5 * h\n",
    "                matchedFaceID = None\n",
    "\n",
    "                for faceID in faceTrackers.keys():\n",
    "                    tracked_position = faceTrackers[faceID].get_position()\n",
    "\n",
    "                    t_x = int(tracked_position.left())\n",
    "                    t_y = int(tracked_position.top())\n",
    "                    t_w = int(tracked_position.width())\n",
    "                    t_h = int(tracked_position.height())\n",
    "\n",
    "                    t_x_bar = t_x + 0.5 * t_w\n",
    "                    t_y_bar = t_y + 0.5 * t_h\n",
    "\n",
    "                    #if face center in tracked bbox and tracked center in face bbox we approved it\n",
    "                    if (\n",
    "                        (t_x <= x_bar <= (t_x + t_w))\n",
    "                        and (t_y <= y_bar <= (t_y + t_h))\n",
    "                        and (x <= t_x_bar <= (x + w))\n",
    "                        and (y <= t_y_bar <= (y + h))\n",
    "                    ):\n",
    "                        matchedFaceID = faceID\n",
    "\n",
    "                if matchedFaceID is None:\n",
    "                    currentFaceID += 1\n",
    "                    tracker = dlib.correlation_tracker()\n",
    "                    tracker.start_track(\n",
    "                        frame,\n",
    "                        dlib.rectangle(x - 10, y - 20, x + w + 10, y + h + 20),\n",
    "                    )\n",
    "\n",
    "                    faceTrackers[currentFaceID] = tracker\n",
    "                    t_f = threading.Thread(\n",
    "                        target=FaceRecognition,\n",
    "                        args=(faceNames, currentFaceID, frame),\n",
    "                        daemon=True,\n",
    "                    )\n",
    "                    t_f.start()\n",
    "\n",
    "\n",
    "        for faceID in faceTrackers.keys():\n",
    "            tracked_position = faceTrackers[faceID].get_position()\n",
    "\n",
    "            t_x = int(tracked_position.left())\n",
    "            t_y = int(tracked_position.top())\n",
    "            t_w = int(tracked_position.width())\n",
    "            t_h = int(tracked_position.height())\n",
    "\n",
    "            cv.rectangle(\n",
    "                resultFrame, (t_x, t_y), (t_x + t_w, t_y + t_h), (0, 255, 0), 2\n",
    "            )\n",
    "\n",
    "            if faceID in faceNames.keys():\n",
    "                cv.putText(\n",
    "                    resultFrame,\n",
    "                    faceNames[faceID],\n",
    "                    (int(t_x + t_w / 2), int(t_y)),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (255, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "            else:\n",
    "                cv.putText(\n",
    "                    resultFrame,\n",
    "                    \"Detecting\",\n",
    "                    (int(t_x + t_w / 2), int(t_y)),\n",
    "                    cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5,\n",
    "                    (255, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        #writer.write(resultFrame)\n",
    "        cv.imshow(\"result\", resultFrame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0be9cd94-90d0-40e9-a235-5ce3a5fe2a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-04-17 23:10:35 - ⚠️ Representations for images in 200classes_data/train folder were previously stored in representations_facenet.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "24-04-17 23:10:35 - There are 1069 representations found in representations_facenet.pkl\n",
      "24-04-17 23:10:36 - find function lasts 0.9274899959564209 seconds\n"
     ]
    }
   ],
   "source": [
    "face_tracking_and_recognition(cap)\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e6c3e-5428-4796-878b-f1666e27947f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
